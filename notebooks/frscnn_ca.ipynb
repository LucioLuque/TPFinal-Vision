{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe38e4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lucio\\Documents\\entornos\\env3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\", \"src\")))\n",
    "import dataset\n",
    "from models import FSRCNN_CA\n",
    "import metrics\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e112df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset.load_general100_dataset()\n",
    "img_arr = [img[\"image\"] for img in ds[\"train\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282e7fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Convertir imágenes PIL a arrays BGR (formato OpenCV)\n",
    "img_sample = img_arr[0:100]\n",
    "img_sample_cv2 = [dataset.pil_to_cv2(img) for img in img_sample]\n",
    "\n",
    "# Paso 2: Augmentación con escalado y rotación usando OpenCV\n",
    "args_augment_fsrcnn = [[0.9, 0.8, 0.7, 0.6], [90, 180, 270]]\n",
    "augmented_images_cv2 = dataset.augment_data_cv2(img_sample_cv2, *args_augment_fsrcnn)\n",
    "\n",
    "# Paso 3: Parámetros para generación de parches lazy\n",
    "upsample_factor = 2\n",
    "patch_size = 10\n",
    "stride = 5\n",
    "use_deconv = True\n",
    "\n",
    "# Paso 4: DataLoaders con LazyPatchDatasetCV2\n",
    "train_loader, val_loader = dataset.lazy_train_val_dataloaders_cv2(\n",
    "    images=augmented_images_cv2,\n",
    "    scale_factor=upsample_factor,\n",
    "    patch_size=patch_size,\n",
    "    stride=stride,\n",
    "    use_deconv=use_deconv,\n",
    "    batch_size=512,\n",
    "    num_workers=6,\n",
    "    seed=42,\n",
    "    val_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb97193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "def train_sr_model(model, train_loader, val_loader, num_epochs=10, lr=1e-4, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "    scaler = GradScaler('cuda')\n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    psnr_list = []\n",
    "    ssim_list = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "            lr_batch, hr_batch = batch\n",
    "            lr_batch, hr_batch = lr_batch.to(device), hr_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast('cuda'):\n",
    "                sr_batch = model(lr_batch)\n",
    "                loss = criterion(sr_batch, hr_batch)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        print(f\"[Epoch {epoch+1}] Train Loss: {avg_train_loss:.6f}\")\n",
    "        train_loss.append(avg_train_loss)\n",
    "\n",
    "        # VALIDACIÓN\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        psnr_total, ssim_total = 0.0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_batch in val_loader:\n",
    "                lr_val, hr_val = val_batch\n",
    "                lr_val, hr_val = lr_val.to(device), hr_val.to(device)\n",
    "                with autocast('cuda'):\n",
    "                    sr_val = model(lr_val)\n",
    "                    loss = criterion(sr_val, hr_val)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                for i in range(sr_val.shape[0]):\n",
    "                    sr_img = sr_val[i].squeeze().detach().cpu().numpy()\n",
    "                    hr_img = hr_val[i].squeeze().detach().cpu().numpy()\n",
    "\n",
    "                    sr_img = np.clip(sr_img, 0.0, 1.0)\n",
    "                    hr_img = np.clip(hr_img, 0.0, 1.0)\n",
    "\n",
    "                    psnr = metrics.psnr(hr_img, sr_img, data_range=1.0)\n",
    "                    ssim = metrics.ssim(hr_img, sr_img, data_range=1.0)\n",
    "\n",
    "                    psnr_total += psnr\n",
    "                    ssim_total += ssim\n",
    "        avg_psnr = psnr_total / len(val_loader)\n",
    "        avg_ssim = ssim_total / len(val_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(f\"[Epoch {epoch+1}] Val Loss: {avg_val_loss:.6f}, PSNR: {avg_psnr:.4f}, SSIM: {avg_ssim:.4f}\")\n",
    "        valid_loss.append(avg_val_loss)\n",
    "        psnr_list.append(avg_psnr)\n",
    "        ssim_list.append(avg_ssim)\n",
    "\n",
    "    return train_loss, valid_loss, psnr_list, ssim_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b47105e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "FSRCNN_CA                                               [1, 1, 20, 20]            --\n",
       "├─Sequential: 1-1                                       [1, 56, 10, 10]           --\n",
       "│    └─Conv2d: 2-1                                      [1, 56, 10, 10]           1,456\n",
       "│    └─PReLU: 2-2                                       [1, 56, 10, 10]           56\n",
       "├─Sequential: 1-2                                       [1, 12, 10, 10]           --\n",
       "│    └─Conv2d: 2-3                                      [1, 12, 10, 10]           684\n",
       "│    └─PReLU: 2-4                                       [1, 12, 10, 10]           12\n",
       "├─RIR: 1-3                                              [1, 12, 10, 10]           --\n",
       "│    └─Sequential: 2-5                                  [1, 12, 10, 10]           --\n",
       "│    │    └─RCAB: 3-1                                   [1, 12, 10, 10]           2,653\n",
       "│    │    └─RCAB: 3-2                                   [1, 12, 10, 10]           2,653\n",
       "│    │    └─RCAB: 3-3                                   [1, 12, 10, 10]           2,653\n",
       "│    │    └─RCAB: 3-4                                   [1, 12, 10, 10]           2,653\n",
       "│    │    └─Conv2d: 3-5                                 [1, 12, 10, 10]           1,308\n",
       "├─Sequential: 1-4                                       [1, 56, 10, 10]           --\n",
       "│    └─Conv2d: 2-6                                      [1, 56, 10, 10]           728\n",
       "│    └─PReLU: 2-7                                       [1, 56, 10, 10]           56\n",
       "├─ConvTranspose2d: 1-5                                  [1, 1, 20, 20]            4,537\n",
       "=========================================================================================================\n",
       "Total params: 19,449\n",
       "Trainable params: 19,449\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 3.28\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.29\n",
       "Params size (MB): 0.08\n",
       "Estimated Total Size (MB): 0.37\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FSRCNN_CA(scale=2)\n",
    "upsample_factor = 2\n",
    "patch_size = 10\n",
    "summary(model, input_size=(1, 1, patch_size, patch_size))  # también 10x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee50137",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, val_loss, psnr_list, ssim_list= train_sr_model(model, train_loader, val_loader, num_epochs=10, lr=1e-4)\n",
    "# torch.save(model.state_dict(), \"fsrcnn_model.pth\")\n",
    "# HACER SAFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8051d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the train loss and validation loss evolution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss, label='Train', color='blue')\n",
    "plt.plot(val_loss, label='Validation', color='orange')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MCE Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8573fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(psnr_list, label='PSNR', color='green')\n",
    "plt.plot(ssim_list, label='SSIM', color='red')\n",
    "plt.title('PSNR and SSIM Evolution')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env3)",
   "language": "python",
   "name": "env3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
